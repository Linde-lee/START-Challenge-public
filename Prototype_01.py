import streamlit as st
import os
import pdfplumber
import tempfile
from transformers import pipeline
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from haystack.nodes import FARMReader, TransformersReader
from haystack.pipelines import ExtractiveQAPipeline
from haystack.document_stores import InMemoryDocumentStore
from haystack.nodes import PreProcessor

# ========== SETUP MODELS ========== #
@st.cache_resource
def load_translation_pipeline():
    model_name = "Helsinki-NLP/opus-mt-de-zh"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
    return pipeline("translation", model=model, tokenizer=tokenizer, src_lang="de", tgt_lang="zh")

@st.cache_resource
def load_qa_pipeline():
    document_store = InMemoryDocumentStore()
    reader = FARMReader(model_name_or_path="deepset/roberta-base-squad2")
    return ExtractiveQAPipeline(reader=reader, retriever=None), document_store

translation_pipeline = load_translation_pipeline()
qa_pipeline, doc_store = load_qa_pipeline()

# ========== PAGE SETUP ========== #
st.set_page_config(page_title="ğŸ“„ PDF åˆ° ä¸­æ–‡è§£é‡Š", layout="centered")
st.title("ğŸ“„ å¾·æ–‡PDF âœ ä¸­æ–‡ç¿»è¯‘ + æœ¬åœ°èŠå¤©æœºå™¨äºº")

# ========== FILE UPLOAD ========== #
st.markdown("è¯·ä¸Šä¼ åŒ…å«å¾·æ–‡å†…å®¹çš„PDFæ–‡ä»¶")
pdf_file = st.file_uploader("ä¸Šä¼ åŒ»é™¢è´¦å• PDF", type=["pdf"])

extracted_text = ""
if pdf_file:
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        tmp_file.write(pdf_file.read())
        tmp_path = tmp_file.name

    with pdfplumber.open(tmp_path) as pdf:
        for page in pdf.pages:
            extracted_text += page.extract_text() + "\n"

    st.markdown("### âœ… æå–åˆ°çš„å¾·æ–‡å†…å®¹:")
    st.text_area("åŸå§‹å¾·æ–‡æ–‡æœ¬:", extracted_text, height=200)

    if st.button("â¡ï¸ ç¿»è¯‘ä¸ºä¸­æ–‡"):
        with st.spinner("æ­£åœ¨ç¿»è¯‘..."):
            try:
                chunks = [extracted_text[i:i+500] for i in range(0, len(extracted_text), 500)]
                translated = [translation_pipeline(chunk)[0]['translation_text'] for chunk in chunks]
                final_translation = "\n".join(translated)
                st.session_state.chat_context = final_translation
                st.success("âœ… ç¿»è¯‘å®Œæˆ")
                st.text_area("ç®€ä½“ä¸­æ–‡ç¿»è¯‘:", final_translation, height=200)

                # For chatbot: load into Haystack doc store
                doc_store.write_documents([{"content": final_translation, "meta": {"name": "hospital_bill"}}])
            except Exception as e:
                st.error(f"ç¿»è¯‘é”™è¯¯: {str(e)}")

# ========== QA CHATBOT ========== #
st.markdown("---")
st.markdown("### ğŸ’¬ ä¸­æ–‡èŠå¤©åŠ©æ‰‹ (ä½¿ç”¨ Haystack æœ¬åœ°é—®ç­”ç³»ç»Ÿ)")
user_question = st.text_input("ä½ æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ")
if st.button("å‘é€é—®é¢˜") and user_question:
    if 'chat_context' not in st.session_state:
        st.warning("è¯·å…ˆä¸Šä¼ å¹¶ç¿»è¯‘PDF")
    else:
        with st.spinner("æ­£åœ¨æŸ¥æ‰¾ç­”æ¡ˆ..."):
            try:
                prediction = qa_pipeline.run(
                    query=user_question,
                    documents=doc_store.get_all_documents(),
                    params={"Reader": {"top_k": 1}}
                )
                answer = prediction['answers'][0].answer if prediction['answers'] else "å¯¹ä¸èµ·ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç­”æ¡ˆã€‚"
                st.markdown(f"**å›ç­”ï¼š** {answer}")
            except Exception as e:
                st.error(f"é”™è¯¯: {str(e)}")
